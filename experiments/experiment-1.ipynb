{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc2d6a3d-bafd-4a10-8d0d-31fcd28d73f5",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7126085c-cd44-4dc8-a87f-4fcf858f2cbe",
   "metadata": {},
   "source": [
    "These experiments aim to determine the baseline performance by classifying a test set of standalone question utterances, with (size 90) and without a training set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea69a7c-520e-44d8-a3cb-f2ad109b0ac6",
   "metadata": {},
   "source": [
    "# Libraries and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e9c4da2-4a1d-4785-afaa-a1432f2865e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import openai\n",
    "import tiktoken\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils import calculate_openai_cost\n",
    "\n",
    "# load environment variables from .env\n",
    "load_dotenv()  \n",
    "\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Initialize the OpenAI client w/API key\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# https://platform.openai.com/docs/models\n",
    "GPT_MODEL = os.getenv(\"OPENAI_MODEL\")\n",
    "\n",
    "# https://openai.com/api/pricing/\n",
    "PROMPT_COST_PER_1000 = os.getenv(\"PROMPT_COST_PER_1000\")\n",
    "COMPLETION_COST_PER_1000 = os.getenv(\"COMPLETION_COST_PER_1000\")\n",
    "\n",
    "DATA_DIR = os.getenv(\"DATA_DIR\")\n",
    "DATA_FILE = os.getenv(\"DATA_FILE\")\n",
    "\n",
    "# dataset ref: https://doi.org/10.1017/pds.2023.100\n",
    "data_path_qa = Path(\"../\", DATA_DIR, DATA_FILE)\n",
    "\n",
    "df = pd.read_excel(data_path_qa, usecols=\"F,G,H,O\")\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "SEED = 42\n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32fda76-3048-4960-818a-43d45c268547",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db66baa0-df2d-40f1-b998-f212f35ca5a7",
   "metadata": {},
   "source": [
    "[Relevant Paper](https://doi.org/10.1017/pds.2023.100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78a76734-aa99-4ad4-9240-989157ba3d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create separate DataFrames for each class\n",
    "llq_data = df[df['A-General Type of Questions'] == 'LLQ']\n",
    "gdq_data = df[df['A-General Type of Questions'] == 'GDQ']\n",
    "drq_data = df[df['A-General Type of Questions'] == 'DRQ']\n",
    "\n",
    "# Sample 30% of LLQ, 30% of GDQ, and 30% of DRQ for training\n",
    "llq_train, llq_test = train_test_split(llq_data, test_size=0.3, random_state=SEED)\n",
    "gdq_train, gdq_test = train_test_split(gdq_data, test_size=0.3, random_state=SEED)\n",
    "drq_train, drq_test = train_test_split(drq_data, test_size=0.3, random_state=SEED)\n",
    "\n",
    "# Concatenate the sampled data for training\n",
    "train_sample = pd.concat([llq_train.head(30), gdq_train.head(30), drq_train.head(30)])\n",
    "\n",
    "# Concatenate the sampled data for testing\n",
    "test_sample = pd.concat([llq_test.head(10), gdq_test.head(10), drq_test.head(10)])\n",
    "\n",
    "# Shuffle the training and test samples\n",
    "train_sample = train_sample.sample(frac=1, random_state=SEED).reset_index(drop=True)\n",
    "test_sample = test_sample.sample(frac=1, random_state=SEED).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1548bbbc-d671-4c21-beef-237d54e8cb30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A-General Type of Questions\n",
       "LLQ    1322\n",
       "GDQ     536\n",
       "DRQ     174\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['A-General Type of Questions'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f155e1-51a3-4462-9e28-aa3aeac83f1f",
   "metadata": {},
   "source": [
    "# With Training Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb62a9c7-3a31-4a49-96ca-d06457fc03f0",
   "metadata": {},
   "source": [
    "## Prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdca3798-8fa8-4c1b-a9d7-319bf114572f",
   "metadata": {},
   "source": [
    "### System message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e4d01cb-ba63-4e41-acd5-2f338ddd8a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System Prompt Message Input token size: 1006\n"
     ]
    }
   ],
   "source": [
    "encoding = tiktoken.encoding_for_model(GPT_MODEL)\n",
    "\n",
    "with open(\"../system-message.txt\") as f:\n",
    "    persona_text = f.read()\n",
    "    print(f\"System Prompt Message Input token size: {len(encoding.encode(persona_text))}\")\n",
    "\n",
    "\n",
    "# NB \n",
    "# 1. The content is collected from [https://doi.org/10.1016/j.destud.2016.07.002] Appendix 1\n",
    "# 2. In the prompt, Right/Left Double Quotation Mark (“ ”) to quote Eris instead of Straight Double Quotation Mark (\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd7efb5-24c3-4695-a182-d2bfd0f3811b",
   "metadata": {},
   "source": [
    "### User message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf3ad2c4-fcc3-4902-a62d-bd90da09fe31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Prompt Message Input token size: 2118\n"
     ]
    }
   ],
   "source": [
    "# create train example list\n",
    "train_sample['example'] = train_sample['Questions'] \\\n",
    "                        + ' : ' + train_sample[\"A-General Type of Questions\"] +'\\n' \n",
    "example_txt = ''.join(train_sample['example'])\n",
    "\n",
    "# numbered test qs list\n",
    "ques_list = '\\n'.join(test_sample['Questions'])\n",
    "num_ques_list = '\\n'.join(f\"{i+1}. {question}\" for i, question in enumerate(ques_list.split('\\n')))\n",
    "\n",
    "prompt_train = f\"Classify each of the questions below, delimited by triple backticks, using the taxonomy proposed by Eris. \\\n",
    "Label each question with one of the three categories: Low-level questions, Deep Reasoning Questions, or Generative Design Questions. \\\n",
    "State your reasoning for the assigned label. Format the result as a markdown table.\\n\\\n",
    "```\\n{num_ques_list}\\n```\\nTo help you categorize the questions above, here are some examples \\\n",
    "delimited by triple backticks, each line contains an example that has two segments - question \\\n",
    "and category separated by colon (:)\\n\\n```\\n{example_txt}\\n```\"\n",
    "\n",
    "\n",
    "print(f\"User Prompt Message Input token size: {len(encoding.encode(prompt_train))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00eb0e20-dc94-464a-9f8f-3b940cd38eac",
   "metadata": {},
   "source": [
    "## Experiment 1A\n",
    "\n",
    "Determine baseline performance. Classify a test set of stand-alone question utterances, with a training set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e32dca39-2b52-4588-bdc1-effca951dab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 38.1 ms, sys: 41.7 ms, total: 79.9 ms\n",
      "Wall time: 47.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "c = openai.chat.completions.create(\n",
    "    model=GPT_MODEL,\n",
    "    n=1,\n",
    "    seed=SEED,\n",
    "    temperature=0,\n",
    "    messages=[{\"role\": \"system\", \"content\": persona_text},\n",
    "              {\"role\": \"user\", \"content\": prompt_train}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa8b4102",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import calculate_openai_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff8ff4ba-9330-431c-a3e1-8544bcb04074",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System Fingerprint: None\n",
      "\n",
      "```markdown\n",
      "| Question Number | Question Text                                                                                                      | Category               | Reasoning                                                                                                                                                                                                                   |\n",
      "|-----------------|-------------------------------------------------------------------------------------------------------------------|------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| 1               | So how do you know how much do?                                                                                     | LLQ                    | This question seems to be incomplete or incorrectly transcribed. However, it appears to be seeking specific information, likely about a quantity, which would make it a low-level question.                                   |\n",
      "| 2               | So the fishbone says, what are the possible contributors?                                                           | GDQ                    | This question is asking for multiple possible causes, which is characteristic of divergent thinking and fits the generative design question category.                                                                       |\n",
      "| 3               | Why would you, why would you put that on there if you could swap in the new roll in in a minute?                    | DRQ                    | This question is asking for the rationale behind a decision, which is a deep reasoning question.                                                                                                                            |\n",
      "| 4               | what about cleats, right cleated conveyor cleats, okay, cleated, cleated cleats, check.                              | GDQ                    | The repetition and checking suggest a proposal or negotiation of an idea, which is a generative design question.                                                                                                            |\n",
      "| 5               | But so it's full 15 or whatever, probably right?                                                                    | LLQ                    | This question is seeking verification or clarification of a quantity, which is a low-level question.                                                                                                                        |\n",
      "| 6               | Could you take the candy and slide it on on the wrapper?                                                            | GDQ                    | This question is proposing a method or action, which is characteristic of a generative design question.                                                                                                                     |\n",
      "| 7               | Why would I do that?                                                                                                | DRQ                    | This question is asking for the rationale behind an action, which is a deep reasoning question.                                                                                                                             |\n",
      "| 8               | how they wrap candy currently?                                                                                      | DRQ                    | This question is asking about the current procedure, which is a deep reasoning question.                                                                                                                                    |\n",
      "| 9               | How does the very last one behave?                                                                                  | DRQ                    | This question is inquiring about the behavior of an object, which could be interpreted as seeking causal explanation, making it a deep reasoning question.                                                                  |\n",
      "| 10              | But this whole thing has to rotate, right?                                                                          | LLQ                    | This question is seeking verification about a component's function, which is a low-level question.                                                                                                                          |\n",
      "| 11              | So when they're wrapping in one of these candies, have you seen the whole process?                                  | LLQ                    | This question is seeking specific information about whether someone has observed a process, which is a low-level question.                                                                                                  |\n",
      "| 12              | Yeah, but I think, isn't it the same?                                                                               | LLQ                    | This question is seeking verification or clarification, which is a low-level question.                                                                                                                                      |\n",
      "| 13              | So is the main assumption right now that the wrapper will stick?                                                    | LLQ                    | This question is seeking verification of an assumption, which is a low-level question.                                                                                                                                      |\n",
      "| 14              | how are you going to intersection things that are exactly the same, you can offset didn't have to be dead center?   | GDQ                    | This question is proposing a method and asking for alternatives, which is characteristic of a generative design question.                                                                                                   |\n",
      "| 15              | How are you going to keep rolling and pulling it?                                                                   | GDQ                    | This question is asking for a method to achieve a goal, which is a generative design question.                                                                                                                              |\n",
      "| 16              | How was the candy being ejected from your machine.                                                                  | DRQ                    | This question is asking about the procedure of a machine, which is a deep reasoning question.                                                                                                                              |\n",
      "| 17              | Can I do this stuff?                                                                                                | LLQ                    | This question is seeking permission or capability verification, which is a low-level question.                                                                                                                              |\n",
      "| 18              | Makes sense? Right?                                                                                                 | LLQ                    | This question is seeking confirmation or understanding, which is a low-level question.                                                                                                                                      |\n",
      "| 19              | What kind of processes out there now?                                                                               | DRQ                    | This question is asking about the current state of processes, which is a deep reasoning question.                                                                                                                           |\n",
      "| 20              | Because these paper will come on to the stage right?                                                                | LLQ                    | This question is seeking verification about a process step, which is a low-level question.                                                                                                                                  |\n",
      "| 21              | my question I see the viability on your automated rolling, rolling adjustable cutter minus one reliability grid system reliability, I can question you Why did you put grid | DRQ                    | This question is asking for the rationale behind a design decision, which is a deep reasoning question.                                                                                                                     |\n",
      "| 22              | What function is providing?                                                                                         | LLQ                    | This question is seeking clarification on the function of an object, which is a low-level question.                                                                                                                         |\n",
      "| 23              | What's gonna happen?                                                                                                | GDQ                    | This question is asking about possible outcomes, which is characteristic of a generative design question.                                                                                                                   |\n",
      "| 24              | so what's happening here at the end of this conveyor belt, tell me a little bit more physically and act? What would happen in terms of how this thing gets pushed in the plastic? | DRQ                    | This question is asking for a detailed explanation of a process, which is a deep reasoning question.                                                                                                                        |\n",
      "| 25              | You're sure safety already by other guarding? What is the purpose of this box?                                      | LLQ                    | This question is seeking clarification on the purpose of an object, which is a low-level question.                                                                                                                          |\n",
      "| 26              | And is this manual pushing? Or is this a motor pushing?                                                             | LLQ                    | This question is seeking specific information about the method of operation, which is a low-level question.                                                                                                                 |\n",
      "| 27              | So so maybe, well, and then also, how are you going to then finalize the closure?                                   | GDQ                    | This question is asking for a method to achieve a specific goal, which is a generative design question.                                                                                                                     |\n",
      "| 28              | So how do we animate this?                                                                                          | GDQ                    | This question is asking for methods to achieve animation, which is a generative design question.                                                                                                                            |\n",
      "| 29              | Or is it something that we can outsource to a company?                                                              | GDQ                    | This question is proposing an alternative solution, which is a generative design question.                                                                                                                                  |\n",
      "| 30              | do you want to a machine to produce 15 to 20 pieces of candy per minute and currently they're doing what is it?     | LLQ                    | This question is seeking specific information about current production rates, which is a low-level question.                                                                                                                |\n",
      "```\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'CompletionUsage' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSystem Fingerprint: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mc\u001b[38;5;241m.\u001b[39msystem_fingerprint\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(c\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent)\n\u001b[0;32m----> 4\u001b[0m cost, prompt_tokens, completion_tokens, total_tokens \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_openai_cost\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43musage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPROMPT_COST_PER_1000\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCOMPLETION_COST_PER_1000\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal cost: $\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcost\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.5f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrompt tokens: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprompt_tokens\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/protocol-research/git-repo/AI-Assisted-Protocol-Analysis-in-Design-Research/experiments/utils.py:8\u001b[0m, in \u001b[0;36mcalculate_openai_cost\u001b[0;34m(usage, prompt_cost_per_1000, completion_cost_per_1000)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_openai_cost\u001b[39m(usage, prompt_cost_per_1000, completion_cost_per_1000):\n\u001b[0;32m----> 8\u001b[0m     prompt_tokens \u001b[38;5;241m=\u001b[39m \u001b[43musage\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprompt_tokens\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      9\u001b[0m     completion_tokens \u001b[38;5;241m=\u001b[39m usage[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcompletion_tokens\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     10\u001b[0m     total_tokens \u001b[38;5;241m=\u001b[39m usage[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_tokens\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: 'CompletionUsage' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "print(f\"System Fingerprint: {c.system_fingerprint}\\n\")\n",
    "print(c.choices[0].message.content)\n",
    "\n",
    "cost, prompt_tokens, completion_tokens, total_tokens = calculate_openai_cost(c.usage, PROMPT_COST_PER_1000, COMPLETION_COST_PER_1000)\n",
    "\n",
    "print(f\"Total cost: ${cost:.5f}\")\n",
    "print(f\"Prompt tokens: {prompt_tokens}\")\n",
    "print(f\"Completion tokens: {completion_tokens}\")\n",
    "print(f\"Total tokens: {total_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d02a388-592e-4162-a231-2540d3612b1d",
   "metadata": {},
   "source": [
    "# Without Training Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb3dfb5-1371-448e-8959-9fbc6a787b4e",
   "metadata": {},
   "source": [
    "## Prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b337c1-cd11-4d08-8826-b86a93a20b88",
   "metadata": {},
   "source": [
    "### User message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79ac6263-1157-4194-b435-0efeeef420d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Prompt Message Input token size: 544\n"
     ]
    }
   ],
   "source": [
    "prompt_no_train = f\"Classify each of the questions below, delimited by triple backticks, using the taxonomy proposed by Eris. \\\n",
    "Label each question with one of the three categories: Low-level questions, Deep Reasoning Questions, or Generative Design Questions. \\\n",
    "State your reasoning for the assigned label. Format the result as a markdown table.\\n\\n \\\n",
    "```\\n{num_ques_list}\\n```\"\n",
    "\n",
    "print(f\"User Prompt Message Input token size: {len(encoding.encode(prompt_no_train))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb99e6d-d721-4e0e-9623-1b1bc0aacc6b",
   "metadata": {},
   "source": [
    "## Experiment 1B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d4eb83-067c-4f6e-abd1-f02dc9830adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "c = openai.chat.completions.create(\n",
    "    model=GPT_MODEL,\n",
    "    n=1,\n",
    "    seed=SEED,\n",
    "    temperature=0,\n",
    "    messages=[{\"role\": \"system\", \"content\": persona_text},\n",
    "              {\"role\": \"user\", \"content\": prompt_no_train}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b2fc73-6b0f-4c7c-b3a5-bdfc288b60a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"System Fingerprint: {c.system_fingerprint}\\n\")\n",
    "print(c.choices[0].message.content)\n",
    "\n",
    "cost, prompt_tokens, completion_tokens, total_tokens = calculate_openai_cost(c.usage, PROMPT_COST_PER_1000, COMPLETION_COST_PER_1000)\n",
    "\n",
    "print(f\"Total cost: ${cost:.5f}\")\n",
    "print(f\"Prompt tokens: {prompt_tokens}\")\n",
    "print(f\"Completion tokens: {completion_tokens}\")\n",
    "print(f\"Total tokens: {total_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0209b0-d41c-42cb-a730-d447b85385c7",
   "metadata": {},
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84290713-674e-4abb-8be6-90faefef9c55",
   "metadata": {},
   "source": [
    "| Testing set: question number and utterance                                                                                                                          | Human   | AI /woT | AI /wT |\n",
    "| ------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --- | ------- | ------ |\n",
    "| 1\\. So how do you know how much do?                                                                                                                                 | DRQ | LLQ     | DRQ    |\n",
    "| 2\\. …what are the possible contributors?                                                                                                                            | GDQ | GDQ     | GDQ    |\n",
    "| 3\\. Why would you put that on there if you could swap in the new roll in a minute?                                                                                  | DRQ | DRQ     | DRQ    |\n",
    "| 4\\. What about cleats, right cleated conveyor cleats?                                                                                                               | GDQ | GDQ     | GDQ    |\n",
    "| 5\\. But so it's full 15 or whatever, probably right?                                                                                                                | LLQ | LLQ     | LLQ    |\n",
    "| 6\\. Could you take the candy and slide it on the wrapper?                                                                                                           | LLQ | GDQ     | GDQ    |\n",
    "| 7\\. Why would I do that?                                                                                                                                            | DRQ | DRQ     | DRQ    |\n",
    "| 8\\. How they wrap candy currently?                                                                                                                                  | DRQ | LLQ     | DRQ    |\n",
    "| 9\\. How does the very last one behave?                                                                                                                              | GDQ | LLQ     | DRQ    |\n",
    "| 10\\. But this whole thing has to rotate, right?                                                                                                                     | LLQ | LLQ     | LLQ    |\n",
    "| 11\\. So when they're wrapping in one of these candies, have you seen the whole process?                                                                             | LLQ | LLQ     | LLQ    |\n",
    "| 12\\. Yeah, but I think, isn't it the same?                                                                                                                          | GDQ | LLQ     | LLQ    |\n",
    "| 13\\. So is the main assumption right now that the wrapper will stick?                                                                                               | LLQ | LLQ     | LLQ    |\n",
    "| 14\\. How are you going to intersection things that are exactly the same…?                                                                                           | GDQ | GDQ     | GDQ    |\n",
    "| 15\\. How are you going to keep rolling and pulling it?                                                                                                              | GDQ | GDQ     | GDQ    |\n",
    "| 16\\. How was the candy being ejected from your machine.                                                                                                             | DRQ | LLQ     | DRQ    |\n",
    "| 17\\. Can I do this stuff?                                                                                                                                           | LLQ | LLQ     | LLQ    |\n",
    "| 18\\. Makes sense? Right?                                                                                                                                            | LLQ | LLQ     | LLQ    |\n",
    "| 19\\. What kind of processes out there now?                                                                                                                          | DRQ | LLQ     | DRQ    |\n",
    "| 20\\. Because these paper will come on to the stage right?                                                                                                           | LLQ | LLQ     | LLQ    |\n",
    "| 21\\. …Why did you put grid?                                                                                                                                         | DRQ | DRQ     | DRQ    |\n",
    "| 22\\. What function is providing?                                                                                                                                    | DRQ | LLQ     | LLQ    |\n",
    "| 23\\. What's gonna happen?                                                                                                                                           | GDQ | DRQ     | GDQ    |\n",
    "| 24\\. So what's happening here at the end of this conveyor belt, tell me a little bit more …What would happen in terms of how this thing gets pushed in the plastic? | DRQ | LLQ     | DRQ    |\n",
    "| 25\\. …What is the purpose of this box?                                                                                                                              | DRQ | LLQ     | LLQ    |\n",
    "| 26\\. And is this manual pushing? Or .. a motor pushing?                                                                                                             | LLQ | LLQ     | LLQ    |\n",
    "| 27…How are you going to then finalize the closure?                                                                                                                  | GDQ | GDQ     | GDQ    |\n",
    "| 28. So how do we animate this?                                                                                                                                      | GDQ | GDQ     | GDQ    |\n",
    "| 29\\. Or is it something that we can outsource to a company?                                                                                                         | GDQ | LLQ     | GDQ    |\n",
    "| 30\\. Do you want to a machine to produce 15 to 20 pieces of candy per min and currently they're doing what is it?                                                   | LLQ | LLQ     | LLQ    |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9b07eb",
   "metadata": {},
   "source": [
    "\n",
    "- GPT-4 generated labels align more closely with the human labels when a training set is provided - 83% when training set size is 90; compared to 60% alignment where no training set is provided. Therefore, training set could be useful."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
