{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dff2e85-7279-4a27-9c49-203899825d64",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d57a02-0c8b-4464-915e-f6b92a6ba67e",
   "metadata": {},
   "source": [
    "The goal of this experiment is to determine the sensitivity of the results across multiple “runs” of the experiment.\n",
    "\n",
    "- Using the training set sizes of 60 and 90, as determined from Experiment 2, the labelling task was repeated once again, independently run 50 times, for each case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b5f08b-b55a-4462-9986-c353db48978f",
   "metadata": {},
   "source": [
    "# Libraries and Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9f9ceb2-9b0d-4106-819c-8fa2279d277f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import random\n",
    "import openai\n",
    "import tiktoken\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils import calculate_openai_cost\n",
    "\n",
    "\n",
    "# load environment variables from .env\n",
    "load_dotenv()  \n",
    "\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Initialize the OpenAI client w/API key\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# https://platform.openai.com/docs/models\n",
    "GPT_MODEL = os.getenv(\"OPENAI_MODEL\")\n",
    "\n",
    "# https://openai.com/api/pricing/\n",
    "PROMPT_COST_PER_1000 = os.getenv(\"PROMPT_COST_PER_1000\")\n",
    "COMPLETION_COST_PER_1000 = os.getenv(\"COMPLETION_COST_PER_1000\")\n",
    "\n",
    "DATA_DIR = os.getenv(\"DATA_DIR\")\n",
    "DATA_FILE = os.getenv(\"DATA_FILE\")\n",
    "\n",
    "# dataset ref: https://doi.org/10.1017/pds.2023.100\n",
    "data_path_qa = Path(\"../\", DATA_DIR, DATA_FILE)\n",
    "\n",
    "df = pd.read_excel(data_path_qa, usecols=\"F,G,H,O\")\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "\n",
    "SEED = 42\n",
    "SEED_EXPERIMENTS = [0, 1, 2, 3, 4, 42, 100, 123, 420, 999]\n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11b316b-a99a-4036-905b-f24a23a7837f",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2581ba-777d-4369-b2f7-ede54ddb8a17",
   "metadata": {},
   "source": [
    "[Relevant Paper](https://doi.org/10.1017/pds.2023.100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "594e10c0-9b62-4b73-ba10-87d128898f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create separate DataFrames for each class\n",
    "llq_data = df[df['A-General Type of Questions'] == 'LLQ']\n",
    "gdq_data = df[df['A-General Type of Questions'] == 'GDQ']\n",
    "drq_data = df[df['A-General Type of Questions'] == 'DRQ']\n",
    "\n",
    "# Sample 1/3 of LLQ, 1/3 of GDQ, and 1/3 of DRQ for training\n",
    "llq_train, llq_test = train_test_split(llq_data, test_size=0.3, random_state=SEED)\n",
    "gdq_train, gdq_test = train_test_split(gdq_data, test_size=0.3, random_state=SEED)\n",
    "drq_train, drq_test = train_test_split(drq_data, test_size=0.3, random_state=SEED)\n",
    "\n",
    "# Concatenate the sampled data for testing\n",
    "test_sample = pd.concat([llq_test.head(10), gdq_test.head(10), drq_test.head(10)])\n",
    "test_sample = test_sample.sample(frac=1, random_state=SEED).reset_index(drop=True)\n",
    "\n",
    "def get_train_sample(num_sample):\n",
    "    num_unit = int(num_sample / 3)\n",
    "    # Concatenate the sampled data for training\n",
    "    train_sample = pd.concat([llq_train.head(num_unit), gdq_train.head(num_unit), drq_train.head(num_unit)])\n",
    "    \n",
    "    # Shuffle the training and test samples\n",
    "    train_sample = train_sample.sample(frac=1, random_state=SEED).reset_index(drop=True)\n",
    "    return train_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93abcf37-8762-435b-83ee-256a38e2fecf",
   "metadata": {},
   "source": [
    "# Prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ad62a4-82e8-4476-b9f0-8ffaa04728a1",
   "metadata": {},
   "source": [
    "## System message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33027296-b7a2-4a49-9465-6be167ba1a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System Prompt Message Input token size: 1006\n"
     ]
    }
   ],
   "source": [
    "encoding = tiktoken.encoding_for_model(GPT_MODEL)\n",
    "\n",
    "with open(\"../system-message.txt\") as f:\n",
    "    persona_text = f.read()\n",
    "    print(f\"System Prompt Message Input token size: {len(encoding.encode(persona_text))}\")\n",
    "\n",
    "\n",
    "# NB \n",
    "# 1. The content is collected from [https://doi.org/10.1016/j.destud.2016.07.002] Appendix 1\n",
    "# 2. In the prompt, Right/Left Double Quotation Mark (“ ”) to quote Eris instead of Straight Double Quotation Mark (\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc70573-2a66-4a75-b1f7-60e4bb771be4",
   "metadata": {},
   "source": [
    "## User Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb25e92b-a8df-448c-983f-ad132aea8bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_sample(num_sample):\n",
    "    num_unit = int(num_sample / 3)\n",
    "    \n",
    "    # Concatenate the sampled data for training\n",
    "    train_sample = pd.concat([llq_train.head(num_unit), gdq_train.head(num_unit), drq_train.head(num_unit)])\n",
    "    \n",
    "    # Shuffle the training and test samples\n",
    "    train_sample = train_sample.sample(frac=1, random_state=SEED).reset_index(drop=True)\n",
    "    return train_sample\n",
    "\n",
    "\n",
    "def get_user_prompt(sample_size):\n",
    "    # create train example list\n",
    "    train_sample = get_train_sample(sample_size)\n",
    "    train_sample['example'] = train_sample['Questions'] \\\n",
    "                        + ' : ' + train_sample[\"A-General Type of Questions\"] +'\\n' \n",
    "    example_txt = ''.join(train_sample['example'])\n",
    "    \n",
    "    # numbered test qs list\n",
    "    ques_list = '\\n'.join(test_sample['Questions'])\n",
    "    num_ques_list = '\\n'.join(f\"{i+1}. {question}\" for i, question in enumerate(ques_list.split('\\n')))\n",
    "\n",
    "    return (\n",
    "        f\"Classify each of the questions below, delimited by triple backticks, using the taxonomy proposed by Eris.\"\n",
    "        f\" Label each question with one of the three categories: Low-level questions (LLQ), Deep Reasoning Questions (DRQ), or Generative Design Questions (GDQ).\"\n",
    "        f\" The result includes only the label, do not state your reasoning for the assigned label. Format the result in JSON. Do not repeat answers.\\n\"\n",
    "        f\"```\\n{num_ques_list}\\n```\\n\"\n",
    "        f\"To help you categorize the questions above, here are some examples delimited by triple backticks, each line contains an example that has two segments - question and category separated by colon (:)\\n\\n\"\n",
    "        f\"```\\n{example_txt}```\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1860c418-d13d-4018-8cbb-fc97f52718fa",
   "metadata": {},
   "source": [
    "# With Training Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d411d5-a632-48f6-be68-2b83a03aa0e9",
   "metadata": {},
   "source": [
    "## Sample Size 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6b81de5-5ded-4433-bb26-bf33e134c3d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Prompt Message Input token size: 2139\n"
     ]
    }
   ],
   "source": [
    "prompt_train = get_user_prompt(90)\n",
    "print(f\"User Prompt Message Input token size: {len(encoding.encode(prompt_train))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5de8de2-ab01-4d36-9fe1-900fcdfa9ef1",
   "metadata": {},
   "source": [
    "### SEED 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac57186-923c-4527-bc16-caa9f9de9ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "c = openai.chat.completions.create(\n",
    "    model=GPT_MODEL,\n",
    "    n=50,\n",
    "    response_format={ \"type\": \"json_object\" },\n",
    "    seed=SEED_EXPERIMENTS[0],\n",
    "    temperature=0,\n",
    "    messages=[{\"role\": \"system\", \"content\": persona_text},\n",
    "              {\"role\": \"user\", \"content\": prompt_train}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff404b2-9f4c-432a-976d-e293f79d94f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"System Fingerprint: {c.system_fingerprint}\\n\")\n",
    "for choice in c.choices:\n",
    "    print(choice.message.content)\n",
    "\n",
    "cost, prompt_tokens, completion_tokens, total_tokens = calculate_openai_cost(c.usage, PROMPT_COST_PER_1000, COMPLETION_COST_PER_1000)\n",
    "\n",
    "print(f\"Total cost: ${cost:.5f}\")\n",
    "print(f\"Prompt tokens: {prompt_tokens}\")\n",
    "print(f\"Completion tokens: {completion_tokens}\")\n",
    "print(f\"Total tokens: {total_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1cf9ff-be1c-44f1-91b5-fc49f5dfaa17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame()\n",
    "\n",
    "for choice in c.choices:\n",
    "    input_text = choice.message.content\n",
    "    # pattern = r'```json\\n(.*?)```'\n",
    "    # match = re.search(pattern, input_text, re.DOTALL) # match.groups(1)[0]\n",
    "    json_result = json.loads(input_text)\n",
    "    df_result = df_result._append(json_result, ignore_index=True)\n",
    "\n",
    "# display(df_result)\n",
    "# columns refer - question number\n",
    "# rows refer - different output\n",
    "print(f\"All results are the same?: {(df_result.apply(pd.Series.nunique, axis=0) == 1).all()}\")\n",
    "\n",
    "df_result.apply(pd.Series.nunique, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03ecb76-3a1f-4aee-9a46-1968047cb50c",
   "metadata": {},
   "source": [
    "### SEED 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049d627d-8f40-415a-94e2-18931da49acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "c = openai.chat.completions.create(\n",
    "    model=GPT_MODEL,\n",
    "    n=50,\n",
    "    response_format={ \"type\": \"json_object\" },\n",
    "    seed=SEED_EXPERIMENTS[1],\n",
    "    temperature=0,\n",
    "    messages=[{\"role\": \"system\", \"content\": persona_text},\n",
    "              {\"role\": \"user\", \"content\": prompt_train}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39501b5d-06c3-4c5f-aa81-70e5c92fa014",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"System Fingerprint: {c.system_fingerprint}\\n\")\n",
    "for choice in c.choices:\n",
    "    print(choice.message.content)\n",
    "\n",
    "cost, prompt_tokens, completion_tokens, total_tokens = calculate_openai_cost(c.usage, PROMPT_COST_PER_1000, COMPLETION_COST_PER_1000)\n",
    "\n",
    "print(f\"Total cost: ${cost:.5f}\")\n",
    "print(f\"Prompt tokens: {prompt_tokens}\")\n",
    "print(f\"Completion tokens: {completion_tokens}\")\n",
    "print(f\"Total tokens: {total_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b220001-119a-43cf-afc0-6b4766b34afa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame()\n",
    "\n",
    "for choice in c.choices:\n",
    "    input_text = choice.message.content\n",
    "    json_result = json.loads(input_text)\n",
    "    df_result = df_result._append(json_result, ignore_index=True)\n",
    "\n",
    "# display(df_result)\n",
    "# columns refer - question number\n",
    "# rows refer - different output\n",
    "print(f\"All results are the same?: {(df_result.apply(pd.Series.nunique, axis=0) == 1).all()}\")\n",
    "df_result.apply(pd.Series.nunique, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd311bd-dffd-4d24-a4ff-6260cf1bbb8a",
   "metadata": {},
   "source": [
    "### SEED 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd23dcd9-0f72-41bc-8e8d-adb71700076d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "c = openai.chat.completions.create(\n",
    "    model=GPT_MODEL,\n",
    "    n=50,\n",
    "    response_format={ \"type\": \"json_object\" },\n",
    "    seed=SEED_EXPERIMENTS[2],\n",
    "    temperature=0,\n",
    "    messages=[{\"role\": \"system\", \"content\": persona_text},\n",
    "              {\"role\": \"user\", \"content\": prompt_train}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72687a55-710b-4e4e-a8ca-4d00556b654c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"System Fingerprint: {c.system_fingerprint}\\n\")\n",
    "for choice in c.choices:\n",
    "    print(choice.message.content)\n",
    "\n",
    "cost, prompt_tokens, completion_tokens, total_tokens = calculate_openai_cost(c.usage, PROMPT_COST_PER_1000, COMPLETION_COST_PER_1000)\n",
    "\n",
    "print(f\"Total cost: ${cost:.5f}\")\n",
    "print(f\"Prompt tokens: {prompt_tokens}\")\n",
    "print(f\"Completion tokens: {completion_tokens}\")\n",
    "print(f\"Total tokens: {total_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5c49d4-5cf7-4bb0-b269-eeab57d9ee14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame()\n",
    "\n",
    "for choice in c.choices:\n",
    "    input_text = choice.message.content\n",
    "    json_result = json.loads(input_text)\n",
    "    df_result = df_result._append(json_result, ignore_index=True)\n",
    "\n",
    "# display(df_result)\n",
    "# columns refer - question number\n",
    "# rows refer - different output\n",
    "print(f\"All results are the same?: {(df_result.apply(pd.Series.nunique, axis=0) == 1).all()}\")\n",
    "df_result.apply(pd.Series.nunique, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964a7202-6611-464e-a0e0-77d043960da0",
   "metadata": {},
   "source": [
    "### SEED 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9d122d-1240-4fc3-ace1-fbfead7657c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "c = openai.chat.completions.create(\n",
    "    model=GPT_MODEL,\n",
    "    n=50,\n",
    "    response_format={ \"type\": \"json_object\" },\n",
    "    seed=SEED_EXPERIMENTS[3],\n",
    "    temperature=0,\n",
    "    messages=[{\"role\": \"system\", \"content\": persona_text},\n",
    "              {\"role\": \"user\", \"content\": prompt_train}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c523f54-ec13-4db2-95dc-5ca56603f7bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"System Fingerprint: {c.system_fingerprint}\\n\")\n",
    "for choice in c.choices:\n",
    "    print(choice.message.content)\n",
    "\n",
    "cost, prompt_tokens, completion_tokens, total_tokens = calculate_openai_cost(c.usage, PROMPT_COST_PER_1000, COMPLETION_COST_PER_1000)\n",
    "\n",
    "print(f\"Total cost: ${cost:.5f}\")\n",
    "print(f\"Prompt tokens: {prompt_tokens}\")\n",
    "print(f\"Completion tokens: {completion_tokens}\")\n",
    "print(f\"Total tokens: {total_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0727875e-6e8d-471e-bf59-6dc5e2f00b86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame()\n",
    "\n",
    "for choice in c.choices:\n",
    "    input_text = choice.message.content\n",
    "    json_result = json.loads(input_text)\n",
    "    df_result = df_result._append(json_result, ignore_index=True)\n",
    "\n",
    "# display(df_result)\n",
    "# columns refer - question number\n",
    "# rows refer - different output\n",
    "print(f\"All results are the same?: {(df_result.apply(pd.Series.nunique, axis=0) == 1).all()}\")\n",
    "df_result.apply(pd.Series.nunique, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaed0ecc-cade-4b2e-bb1f-4fba52bc2ec9",
   "metadata": {},
   "source": [
    "### SEED 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7639c65-453a-4073-9040-a91e2df7c5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "c = openai.chat.completions.create(\n",
    "    model=GPT_MODEL,\n",
    "    n=50,\n",
    "    response_format={ \"type\": \"json_object\" },\n",
    "    seed=SEED_EXPERIMENTS[4],\n",
    "    temperature=0,\n",
    "    messages=[{\"role\": \"system\", \"content\": persona_text},\n",
    "              {\"role\": \"user\", \"content\": prompt_train}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b298e955-c17c-4711-8d4e-44c008d5d554",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"System Fingerprint: {c.system_fingerprint}\\n\")\n",
    "for choice in c.choices:\n",
    "    print(choice.message.content)\n",
    "\n",
    "cost, prompt_tokens, completion_tokens, total_tokens = calculate_openai_cost(c.usage, PROMPT_COST_PER_1000, COMPLETION_COST_PER_1000)\n",
    "\n",
    "print(f\"Total cost: ${cost:.5f}\")\n",
    "print(f\"Prompt tokens: {prompt_tokens}\")\n",
    "print(f\"Completion tokens: {completion_tokens}\")\n",
    "print(f\"Total tokens: {total_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d489e44d-2a20-40dd-a5fd-d49c815c2593",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame()\n",
    "\n",
    "for choice in c.choices:\n",
    "    input_text = choice.message.content\n",
    "    json_result = json.loads(input_text)\n",
    "    df_result = df_result._append(json_result, ignore_index=True)\n",
    "\n",
    "# display(df_result)\n",
    "# columns refer - question number\n",
    "# rows refer - different output\n",
    "print(f\"All results are the same?: {(df_result.apply(pd.Series.nunique, axis=0) == 1).all()}\")\n",
    "df_result.apply(pd.Series.nunique, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250fe6d6-8264-455d-b463-521b58461f4d",
   "metadata": {},
   "source": [
    "### SEED 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a172e33a-968f-4f1e-8187-2ecaf324db8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "c = openai.chat.completions.create(\n",
    "    model=GPT_MODEL,\n",
    "    n=50,\n",
    "    response_format={ \"type\": \"json_object\" },\n",
    "    seed=SEED_EXPERIMENTS[5],\n",
    "    temperature=0,\n",
    "    messages=[{\"role\": \"system\", \"content\": persona_text},\n",
    "              {\"role\": \"user\", \"content\": prompt_train}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c2f67b-ad04-4a15-a132-ab912b4bb457",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"System Fingerprint: {c.system_fingerprint}\\n\")\n",
    "for choice in c.choices:\n",
    "    print(choice.message.content)\n",
    "\n",
    "cost, prompt_tokens, completion_tokens, total_tokens = calculate_openai_cost(c.usage, PROMPT_COST_PER_1000, COMPLETION_COST_PER_1000)\n",
    "\n",
    "print(f\"Total cost: ${cost:.5f}\")\n",
    "print(f\"Prompt tokens: {prompt_tokens}\")\n",
    "print(f\"Completion tokens: {completion_tokens}\")\n",
    "print(f\"Total tokens: {total_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fd3bab-0d63-460f-bc48-d84793a5220f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame()\n",
    "\n",
    "for choice in c.choices:\n",
    "    input_text = choice.message.content\n",
    "    json_result = json.loads(input_text)\n",
    "    df_result = df_result._append(json_result, ignore_index=True)\n",
    "\n",
    "# display(df_result)\n",
    "# columns refer - question number\n",
    "# rows refer - different output\n",
    "print(f\"All results are the same?: {(df_result.apply(pd.Series.nunique, axis=0) == 1).all()}\")\n",
    "df_result.apply(pd.Series.nunique, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ff4b8a-1b40-457b-9dd3-c117a2ebd5ae",
   "metadata": {},
   "source": [
    "### SEED 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8744c97-33f1-4bce-bcad-f58c2e0eb4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "c = openai.chat.completions.create(\n",
    "    model=GPT_MODEL,\n",
    "    n=50,\n",
    "    response_format={ \"type\": \"json_object\" },\n",
    "    seed=SEED_EXPERIMENTS[6],\n",
    "    temperature=0,\n",
    "    messages=[{\"role\": \"system\", \"content\": persona_text},\n",
    "              {\"role\": \"user\", \"content\": prompt_train}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19da7f91-ce13-43fe-b03d-19b8a4f80090",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"System Fingerprint: {c.system_fingerprint}\\n\")\n",
    "for choice in c.choices:\n",
    "    print(choice.message.content)\n",
    "\n",
    "cost, prompt_tokens, completion_tokens, total_tokens = calculate_openai_cost(c.usage, PROMPT_COST_PER_1000, COMPLETION_COST_PER_1000)\n",
    "\n",
    "print(f\"Total cost: ${cost:.5f}\")\n",
    "print(f\"Prompt tokens: {prompt_tokens}\")\n",
    "print(f\"Completion tokens: {completion_tokens}\")\n",
    "print(f\"Total tokens: {total_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee5d425-d0ca-4502-92a6-9c0084663c73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame()\n",
    "\n",
    "for choice in c.choices:\n",
    "    input_text = choice.message.content\n",
    "    json_result = json.loads(input_text)\n",
    "    df_result = df_result._append(json_result, ignore_index=True)\n",
    "\n",
    "# display(df_result)\n",
    "# columns refer - question number\n",
    "# rows refer - different output\n",
    "print(f\"All results are the same?: {(df_result.apply(pd.Series.nunique, axis=0) == 1).all()}\")\n",
    "df_result.apply(pd.Series.nunique, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47038efc-ad2e-4c2f-83a5-c4fdf7efed94",
   "metadata": {},
   "source": [
    "### SEED 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afd6e66-5a48-4e08-939b-ef6443d13ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "c = openai.chat.completions.create(\n",
    "    model=GPT_MODEL,\n",
    "    n=50,\n",
    "    response_format={ \"type\": \"json_object\" },\n",
    "    seed=SEED_EXPERIMENTS[7],\n",
    "    temperature=0,\n",
    "    messages=[{\"role\": \"system\", \"content\": persona_text},\n",
    "              {\"role\": \"user\", \"content\": prompt_train}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76dfd16d-ce9e-4786-8bf3-adaf6d7cd7da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"System Fingerprint: {c.system_fingerprint}\\n\")\n",
    "for choice in c.choices:\n",
    "    print(choice.message.content)\n",
    "\n",
    "cost, prompt_tokens, completion_tokens, total_tokens = calculate_openai_cost(c.usage, PROMPT_COST_PER_1000, COMPLETION_COST_PER_1000)\n",
    "\n",
    "print(f\"Total cost: ${cost:.5f}\")\n",
    "print(f\"Prompt tokens: {prompt_tokens}\")\n",
    "print(f\"Completion tokens: {completion_tokens}\")\n",
    "print(f\"Total tokens: {total_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5d2734-22b3-414f-a075-20330283428c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame()\n",
    "\n",
    "for choice in c.choices:\n",
    "    input_text = choice.message.content\n",
    "    json_result = json.loads(input_text)\n",
    "    df_result = df_result._append(json_result, ignore_index=True)\n",
    "\n",
    "# display(df_result)\n",
    "# columns refer - question number\n",
    "# rows refer - different output\n",
    "print(f\"All results are the same?: {(df_result.apply(pd.Series.nunique, axis=0) == 1).all()}\")\n",
    "df_result.apply(pd.Series.nunique, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef2716a-5bd5-4353-823c-6667ca1265af",
   "metadata": {},
   "source": [
    "### SEED 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d7dc0b-14e2-47c9-8e21-5ba3c8cf0de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "c = openai.chat.completions.create(\n",
    "    model=GPT_MODEL,\n",
    "    n=50,\n",
    "    response_format={ \"type\": \"json_object\" },\n",
    "    seed=SEED_EXPERIMENTS[8],\n",
    "    temperature=0,\n",
    "    messages=[{\"role\": \"system\", \"content\": persona_text},\n",
    "              {\"role\": \"user\", \"content\": prompt_train}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7f9c44-2edf-493e-ab06-19a3db7e684f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"System Fingerprint: {c.system_fingerprint}\\n\")\n",
    "for choice in c.choices:\n",
    "    print(choice.message.content)\n",
    "\n",
    "cost, prompt_tokens, completion_tokens, total_tokens = calculate_openai_cost(c.usage, PROMPT_COST_PER_1000, COMPLETION_COST_PER_1000)\n",
    "\n",
    "print(f\"Total cost: ${cost:.5f}\")\n",
    "print(f\"Prompt tokens: {prompt_tokens}\")\n",
    "print(f\"Completion tokens: {completion_tokens}\")\n",
    "print(f\"Total tokens: {total_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1a13a6-7db6-4474-acea-41e1eefaee49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame()\n",
    "\n",
    "for choice in c.choices:\n",
    "    input_text = choice.message.content\n",
    "    json_result = json.loads(input_text)\n",
    "    df_result = df_result._append(json_result, ignore_index=True)\n",
    "\n",
    "# display(df_result)\n",
    "# columns refer - question number\n",
    "# rows refer - different output\n",
    "print(f\"All results are the same?: {(df_result.apply(pd.Series.nunique, axis=0) == 1).all()}\")\n",
    "df_result.apply(pd.Series.nunique, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50447421-b6c5-4984-b073-2fd4673a6194",
   "metadata": {},
   "source": [
    "### SEED 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9917242c-72b4-4b27-a0c5-d80759336761",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "c = openai.chat.completions.create(\n",
    "    model=GPT_MODEL,\n",
    "    n=50,\n",
    "    response_format={ \"type\": \"json_object\" },\n",
    "    seed=SEED_EXPERIMENTS[9],\n",
    "    temperature=0,\n",
    "    messages=[{\"role\": \"system\", \"content\": persona_text},\n",
    "              {\"role\": \"user\", \"content\": prompt_train}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc1c43c-14ef-4633-81e4-e96cd4b74402",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"System Fingerprint: {c.system_fingerprint}\\n\")\n",
    "for choice in c.choices:\n",
    "    print(choice.message.content)\n",
    "\n",
    "cost, prompt_tokens, completion_tokens, total_tokens = calculate_openai_cost(c.usage, PROMPT_COST_PER_1000, COMPLETION_COST_PER_1000)\n",
    "\n",
    "print(f\"Total cost: ${cost:.5f}\")\n",
    "print(f\"Prompt tokens: {prompt_tokens}\")\n",
    "print(f\"Completion tokens: {completion_tokens}\")\n",
    "print(f\"Total tokens: {total_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7312e437-4e5f-487c-8c9d-df0e8e78a045",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame()\n",
    "\n",
    "for choice in c.choices:\n",
    "    input_text = choice.message.content\n",
    "    json_result = json.loads(input_text)\n",
    "    df_result = df_result._append(json_result, ignore_index=True)\n",
    "\n",
    "# display(df_result)\n",
    "# columns refer - question number\n",
    "# rows refer - different output\n",
    "print(f\"All results are the same?: {(df_result.apply(pd.Series.nunique, axis=0) == 1).all()}\")\n",
    "df_result.apply(pd.Series.nunique, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11150d27-81eb-48f9-8e34-ef3eb1d8b2e0",
   "metadata": {},
   "source": [
    "## Sample size 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d561e28-73a6-4049-a1ca-957849b8f4d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Prompt Message Input token size: 1617\n"
     ]
    }
   ],
   "source": [
    "prompt_train = get_user_prompt(60)\n",
    "print(f\"User Prompt Message Input token size: {len(encoding.encode(prompt_train))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def6c0d5-b06d-40b6-84fb-324afb8ee09b",
   "metadata": {},
   "source": [
    "### SEED 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d786cacd-18f9-49e6-9d10-7d925497af38",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "c = openai.chat.completions.create(\n",
    "    model=GPT_MODEL,\n",
    "    n=50,\n",
    "    response_format={ \"type\": \"json_object\" },\n",
    "    seed=SEED_EXPERIMENTS[0],\n",
    "    temperature=0,\n",
    "    messages=[{\"role\": \"system\", \"content\": persona_text},\n",
    "              {\"role\": \"user\", \"content\": prompt_train}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0ae332-bcd6-4b31-920b-9a370dad3b8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"System Fingerprint: {c.system_fingerprint}\\n\")\n",
    "for choice in c.choices:\n",
    "    print(choice.message.content)\n",
    "\n",
    "cost, prompt_tokens, completion_tokens, total_tokens = calculate_openai_cost(c.usage, PROMPT_COST_PER_1000, COMPLETION_COST_PER_1000)\n",
    "\n",
    "print(f\"Total cost: ${cost:.5f}\")\n",
    "print(f\"Prompt tokens: {prompt_tokens}\")\n",
    "print(f\"Completion tokens: {completion_tokens}\")\n",
    "print(f\"Total tokens: {total_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1900e658-506b-4b31-afbd-4363cc8f5cd6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame()\n",
    "\n",
    "for choice in c.choices:\n",
    "    input_text = choice.message.content\n",
    "    # pattern = r'```json\\n(.*?)```'\n",
    "    # match = re.search(pattern, input_text, re.DOTALL) # match.groups(1)[0]\n",
    "    json_result = json.loads(input_text)\n",
    "    df_result = df_result._append(json_result, ignore_index=True)\n",
    "\n",
    "# display(df_result)\n",
    "# columns refer - question number\n",
    "# rows refer - different output\n",
    "print(f\"All results are the same?: {(df_result.apply(pd.Series.nunique, axis=0) == 1).all()}\")\n",
    "df_result.apply(pd.Series.nunique, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bdfc09-9dd1-4f7d-ac0f-a498b9d62bae",
   "metadata": {},
   "source": [
    "### SEED 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27d7d2b-491a-4f61-92ae-dcfa81660cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "c = openai.chat.completions.create(\n",
    "    model=GPT_MODEL,\n",
    "    n=50,\n",
    "    response_format={ \"type\": \"json_object\" },\n",
    "    seed=SEED_EXPERIMENTS[1],\n",
    "    temperature=0,\n",
    "    messages=[{\"role\": \"system\", \"content\": persona_text},\n",
    "              {\"role\": \"user\", \"content\": prompt_train}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9a92f4-b356-433c-9907-7f628305ba53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"System Fingerprint: {c.system_fingerprint}\\n\")\n",
    "for choice in c.choices:\n",
    "    print(choice.message.content)\n",
    "\n",
    "cost, prompt_tokens, completion_tokens, total_tokens = calculate_openai_cost(c.usage, PROMPT_COST_PER_1000, COMPLETION_COST_PER_1000)\n",
    "\n",
    "print(f\"Total cost: ${cost:.5f}\")\n",
    "print(f\"Prompt tokens: {prompt_tokens}\")\n",
    "print(f\"Completion tokens: {completion_tokens}\")\n",
    "print(f\"Total tokens: {total_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0977d1-8fc1-4986-b8a0-473d74f669a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame()\n",
    "\n",
    "for choice in c.choices:\n",
    "    input_text = choice.message.content\n",
    "    json_result = json.loads(input_text)\n",
    "    df_result = df_result._append(json_result, ignore_index=True)\n",
    "\n",
    "# display(df_result)\n",
    "# columns refer - question number\n",
    "# rows refer - different output\n",
    "print(f\"All results are the same?: {(df_result.apply(pd.Series.nunique, axis=0) == 1).all()}\")\n",
    "df_result.apply(pd.Series.nunique, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73da74f1-bb8c-4111-a49c-ef3a12e2158d",
   "metadata": {},
   "source": [
    "### SEED 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae668ced-c49b-4596-87da-8525dd33b48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "c = openai.chat.completions.create(\n",
    "    model=GPT_MODEL,\n",
    "    n=50,\n",
    "    response_format={ \"type\": \"json_object\" },\n",
    "    seed=SEED_EXPERIMENTS[2],\n",
    "    temperature=0,\n",
    "    messages=[{\"role\": \"system\", \"content\": persona_text},\n",
    "              {\"role\": \"user\", \"content\": prompt_train}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c375f4-5c7a-4d9d-bba9-718c9c3885eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"System Fingerprint: {c.system_fingerprint}\\n\")\n",
    "for choice in c.choices:\n",
    "    print(choice.message.content)\n",
    "\n",
    "cost, prompt_tokens, completion_tokens, total_tokens = calculate_openai_cost(c.usage, PROMPT_COST_PER_1000, COMPLETION_COST_PER_1000)\n",
    "\n",
    "print(f\"Total cost: ${cost:.5f}\")\n",
    "print(f\"Prompt tokens: {prompt_tokens}\")\n",
    "print(f\"Completion tokens: {completion_tokens}\")\n",
    "print(f\"Total tokens: {total_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b5c876-080d-4d97-b8be-0e28c13dd174",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame()\n",
    "\n",
    "for choice in c.choices:\n",
    "    input_text = choice.message.content\n",
    "    json_result = json.loads(input_text)\n",
    "    df_result = df_result._append(json_result, ignore_index=True)\n",
    "\n",
    "# display(df_result)\n",
    "# columns refer - question number\n",
    "# rows refer - different output\n",
    "print(f\"All results are the same?: {(df_result.apply(pd.Series.nunique, axis=0) == 1).all()}\")\n",
    "df_result.apply(pd.Series.nunique, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac92c271-b277-48f2-84f4-9e8c6cc28b3b",
   "metadata": {},
   "source": [
    "### SEED 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2545e1c-bd92-4afc-9a11-5e346fabbf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "c = openai.chat.completions.create(\n",
    "    model=GPT_MODEL,\n",
    "    n=50,\n",
    "    response_format={ \"type\": \"json_object\" },\n",
    "    seed=SEED_EXPERIMENTS[3],\n",
    "    temperature=0,\n",
    "    messages=[{\"role\": \"system\", \"content\": persona_text},\n",
    "              {\"role\": \"user\", \"content\": prompt_train}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd90e966-7396-458e-a554-644e015cd220",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"System Fingerprint: {c.system_fingerprint}\\n\")\n",
    "for choice in c.choices:\n",
    "    print(choice.message.content)\n",
    "\n",
    "cost, prompt_tokens, completion_tokens, total_tokens = calculate_openai_cost(c.usage, PROMPT_COST_PER_1000, COMPLETION_COST_PER_1000)\n",
    "\n",
    "print(f\"Total cost: ${cost:.5f}\")\n",
    "print(f\"Prompt tokens: {prompt_tokens}\")\n",
    "print(f\"Completion tokens: {completion_tokens}\")\n",
    "print(f\"Total tokens: {total_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7777a79a-5761-4354-81f9-702efe39118f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame()\n",
    "\n",
    "for choice in c.choices:\n",
    "    input_text = choice.message.content\n",
    "    json_result = json.loads(input_text)\n",
    "    df_result = df_result._append(json_result, ignore_index=True)\n",
    "\n",
    "# display(df_result)\n",
    "# columns refer - question number\n",
    "# rows refer - different output\n",
    "print(f\"All results are the same?: {(df_result.apply(pd.Series.nunique, axis=0) == 1).all()}\")\n",
    "df_result.apply(pd.Series.nunique, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427dfe29-aec7-4db0-87ce-e7717df8e409",
   "metadata": {},
   "source": [
    "### SEED 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d74673-80dc-4993-af34-db01f0b07ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "c = openai.chat.completions.create(\n",
    "    model=GPT_MODEL,\n",
    "    n=50,\n",
    "    response_format={ \"type\": \"json_object\" },\n",
    "    seed=SEED_EXPERIMENTS[4],\n",
    "    temperature=0,\n",
    "    messages=[{\"role\": \"system\", \"content\": persona_text},\n",
    "              {\"role\": \"user\", \"content\": prompt_train}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15992137-515a-447f-85ef-170a9c14e107",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"System Fingerprint: {c.system_fingerprint}\\n\")\n",
    "for choice in c.choices:\n",
    "    print(choice.message.content)\n",
    "\n",
    "cost, prompt_tokens, completion_tokens, total_tokens = calculate_openai_cost(c.usage, PROMPT_COST_PER_1000, COMPLETION_COST_PER_1000)\n",
    "\n",
    "print(f\"Total cost: ${cost:.5f}\")\n",
    "print(f\"Prompt tokens: {prompt_tokens}\")\n",
    "print(f\"Completion tokens: {completion_tokens}\")\n",
    "print(f\"Total tokens: {total_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef93abb-c143-4605-bcf9-1f40771df8df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame()\n",
    "\n",
    "for choice in c.choices:\n",
    "    input_text = choice.message.content\n",
    "    json_result = json.loads(input_text)\n",
    "    df_result = df_result._append(json_result, ignore_index=True)\n",
    "\n",
    "# display(df_result)\n",
    "# columns refer - question number\n",
    "# rows refer - different output\n",
    "print(f\"All results are the same?: {(df_result.apply(pd.Series.nunique, axis=0) == 1).all()}\")\n",
    "df_result.apply(pd.Series.nunique, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b808246-a577-4b16-981d-d51799b38324",
   "metadata": {},
   "source": [
    "### SEED 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d048736e-e404-49ea-b5c8-eb977e2a5417",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "c = openai.chat.completions.create(\n",
    "    model=GPT_MODEL,\n",
    "    n=50,\n",
    "    response_format={ \"type\": \"json_object\" },\n",
    "    seed=SEED_EXPERIMENTS[5],\n",
    "    temperature=0,\n",
    "    messages=[{\"role\": \"system\", \"content\": persona_text},\n",
    "              {\"role\": \"user\", \"content\": prompt_train}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e02fd2a-fc83-42ae-b1b4-f3a363fe6275",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"System Fingerprint: {c.system_fingerprint}\\n\")\n",
    "for choice in c.choices:\n",
    "    print(choice.message.content)\n",
    "\n",
    "cost, prompt_tokens, completion_tokens, total_tokens = calculate_openai_cost(c.usage, PROMPT_COST_PER_1000, COMPLETION_COST_PER_1000)\n",
    "\n",
    "print(f\"Total cost: ${cost:.5f}\")\n",
    "print(f\"Prompt tokens: {prompt_tokens}\")\n",
    "print(f\"Completion tokens: {completion_tokens}\")\n",
    "print(f\"Total tokens: {total_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc15d37-65a1-49ee-b9c5-2e42a413f7e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame()\n",
    "\n",
    "for choice in c.choices:\n",
    "    input_text = choice.message.content\n",
    "    json_result = json.loads(input_text)\n",
    "    df_result = df_result._append(json_result, ignore_index=True)\n",
    "\n",
    "# display(df_result)\n",
    "# columns refer - question number\n",
    "# rows refer - different output\n",
    "print(f\"All results are the same?: {(df_result.apply(pd.Series.nunique, axis=0) == 1).all()}\")\n",
    "df_result.apply(pd.Series.nunique, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da12617b-2232-4ebc-b6eb-d7b2c58ce54b",
   "metadata": {},
   "source": [
    "### SEED 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ec4095-9c1b-40cb-a28c-234972c24fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "c = openai.chat.completions.create(\n",
    "    model=GPT_MODEL,\n",
    "    n=50,\n",
    "    response_format={ \"type\": \"json_object\" },\n",
    "    seed=SEED_EXPERIMENTS[6],\n",
    "    temperature=0,\n",
    "    messages=[{\"role\": \"system\", \"content\": persona_text},\n",
    "              {\"role\": \"user\", \"content\": prompt_train}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982b5313-d6f5-4c53-990b-af261fb73cff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"System Fingerprint: {c.system_fingerprint}\\n\")\n",
    "for choice in c.choices:\n",
    "    print(choice.message.content)\n",
    "\n",
    "cost, prompt_tokens, completion_tokens, total_tokens = calculate_openai_cost(c.usage, PROMPT_COST_PER_1000, COMPLETION_COST_PER_1000)\n",
    "\n",
    "print(f\"Total cost: ${cost:.5f}\")\n",
    "print(f\"Prompt tokens: {prompt_tokens}\")\n",
    "print(f\"Completion tokens: {completion_tokens}\")\n",
    "print(f\"Total tokens: {total_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95b7502-e7cf-49ce-8c36-30fb6273d635",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame()\n",
    "\n",
    "for choice in c.choices:\n",
    "    input_text = choice.message.content\n",
    "    json_result = json.loads(input_text)\n",
    "    df_result = df_result._append(json_result, ignore_index=True)\n",
    "\n",
    "# display(df_result)\n",
    "# columns refer - question number\n",
    "# rows refer - different output\n",
    "print(f\"All results are the same?: {(df_result.apply(pd.Series.nunique, axis=0) == 1).all()}\")\n",
    "df_result.apply(pd.Series.nunique, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d7cf13-1240-42dd-8232-bf5d7e2d9146",
   "metadata": {},
   "source": [
    "### SEED 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac8aaaa-69f2-4b03-9c4d-0b7183bf5ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "c = openai.chat.completions.create(\n",
    "    model=GPT_MODEL,\n",
    "    n=50,\n",
    "    response_format={ \"type\": \"json_object\" },\n",
    "    seed=SEED_EXPERIMENTS[7],\n",
    "    temperature=0,\n",
    "    messages=[{\"role\": \"system\", \"content\": persona_text},\n",
    "              {\"role\": \"user\", \"content\": prompt_train}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d228b7-1510-40bd-99d2-bc0d3f4e4e6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"System Fingerprint: {c.system_fingerprint}\\n\")\n",
    "for choice in c.choices:\n",
    "    print(choice.message.content)\n",
    "\n",
    "cost, prompt_tokens, completion_tokens, total_tokens = calculate_openai_cost(c.usage, PROMPT_COST_PER_1000, COMPLETION_COST_PER_1000)\n",
    "\n",
    "print(f\"Total cost: ${cost:.5f}\")\n",
    "print(f\"Prompt tokens: {prompt_tokens}\")\n",
    "print(f\"Completion tokens: {completion_tokens}\")\n",
    "print(f\"Total tokens: {total_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a16925-9720-4d7f-941a-1f369e89bb48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame()\n",
    "\n",
    "for choice in c.choices:\n",
    "    input_text = choice.message.content\n",
    "    json_result = json.loads(input_text)\n",
    "    df_result = df_result._append(json_result, ignore_index=True)\n",
    "\n",
    "# display(df_result)\n",
    "# columns refer - question number\n",
    "# rows refer - different output\n",
    "print(f\"All results are the same?: {(df_result.apply(pd.Series.nunique, axis=0) == 1).all()}\")\n",
    "df_result.apply(pd.Series.nunique, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91070501-397e-4d24-9707-7397c0c2e510",
   "metadata": {},
   "source": [
    "### SEED 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c8169a-2035-4259-b2c0-b58e934e750c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "c = openai.chat.completions.create(\n",
    "    model=GPT_MODEL,\n",
    "    n=50,\n",
    "    response_format={ \"type\": \"json_object\" },\n",
    "    seed=SEED_EXPERIMENTS[8],\n",
    "    temperature=0,\n",
    "    messages=[{\"role\": \"system\", \"content\": persona_text},\n",
    "              {\"role\": \"user\", \"content\": prompt_train}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1fa687-e1e9-42b1-b315-e81cf2225ab4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"System Fingerprint: {c.system_fingerprint}\\n\")\n",
    "for choice in c.choices:\n",
    "    print(choice.message.content)\n",
    "\n",
    "cost, prompt_tokens, completion_tokens, total_tokens = calculate_openai_cost(c.usage, PROMPT_COST_PER_1000, COMPLETION_COST_PER_1000)\n",
    "\n",
    "print(f\"Total cost: ${cost:.5f}\")\n",
    "print(f\"Prompt tokens: {prompt_tokens}\")\n",
    "print(f\"Completion tokens: {completion_tokens}\")\n",
    "print(f\"Total tokens: {total_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f458ee-ed15-45fd-a688-d248fc50dbdb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame()\n",
    "\n",
    "for choice in c.choices:\n",
    "    input_text = choice.message.content\n",
    "    json_result = json.loads(input_text)\n",
    "    df_result = df_result._append(json_result, ignore_index=True)\n",
    "\n",
    "# display(df_result)\n",
    "# columns refer - question number\n",
    "# rows refer - different output\n",
    "print(f\"All results are the same?: {(df_result.apply(pd.Series.nunique, axis=0) == 1).all()}\")\n",
    "df_result.apply(pd.Series.nunique, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf8642b-a135-41f6-82fd-bc0f552cefe8",
   "metadata": {},
   "source": [
    "### SEED 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ff8e18-a8fd-4232-931a-07b8adac499c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "c = openai.chat.completions.create(\n",
    "    model=GPT_MODEL,\n",
    "    n=50,\n",
    "    response_format={ \"type\": \"json_object\" },\n",
    "    seed=SEED_EXPERIMENTS[9],\n",
    "    temperature=0,\n",
    "    messages=[{\"role\": \"system\", \"content\": persona_text},\n",
    "              {\"role\": \"user\", \"content\": prompt_train}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc07b4e-2206-4cbe-bd7b-ec8cb6f26def",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"System Fingerprint: {c.system_fingerprint}\\n\")\n",
    "for choice in c.choices:\n",
    "    print(choice.message.content)\n",
    "\n",
    "cost, prompt_tokens, completion_tokens, total_tokens = calculate_openai_cost(c.usage, PROMPT_COST_PER_1000, COMPLETION_COST_PER_1000)\n",
    "\n",
    "print(f\"Total cost: ${cost:.5f}\")\n",
    "print(f\"Prompt tokens: {prompt_tokens}\")\n",
    "print(f\"Completion tokens: {completion_tokens}\")\n",
    "print(f\"Total tokens: {total_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3f133d-5c8e-4a50-99b9-140c8fb7928c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame()\n",
    "\n",
    "for choice in c.choices:\n",
    "    input_text = choice.message.content\n",
    "    json_result = json.loads(input_text)\n",
    "    df_result = df_result._append(json_result, ignore_index=True)\n",
    "\n",
    "# display(df_result)\n",
    "# columns refer - question number\n",
    "# rows refer - different output\n",
    "print(f\"All results are the same?: {(df_result.apply(pd.Series.nunique, axis=0) == 1).all()}\")\n",
    "df_result.apply(pd.Series.nunique, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0006cccc-400e-483f-aa13-990dfa7188e4",
   "metadata": {},
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b87fd8-461a-4358-a090-ffdc10a3322f",
   "metadata": {},
   "source": [
    "|     |  |           Human label          |                     | |        AI, training w/60 Qs              |                     |  |      AI, training w/90 Qs               |                     |\n",
    "| --- | :----------: | :-----------------: | :-----------------: | :------------------: | :-----------------: | :-----------------: | :------------------: | :-----------------: | :-----------------: |\n",
    "|     |    LLQ    |    DRQ    |    GDQ    |    LLQ    |    DRQ    |    GDQ    |    LLQ    |    DRQ    |    GDQ    |\n",
    "| Q1  | 1 |   |   |  1   |      |      |  1   |      |   |\n",
    "| Q2  |   |   | 1 |      |      |  1   |      |      | 1 |\n",
    "| Q3  |   | 1 |   |      | 1    |      |      | 1    |   |\n",
    "| Q4  |   |   | 1 |      |      | 1    |      |      | 1 |\n",
    "| Q5  | 1 |   |   | 1    |      |      | 1    |      |   |\n",
    "| Q6  | 1 |   |   |      | 0.24 | 0.76 |      |      | 1 |\n",
    "| Q7  |   | 1 |   |      | 1    |      |      | 1    |   |\n",
    "| Q8  |   | 1 |   |      | 1    |      | 1    |      |   |\n",
    "| Q9  |   |   | 1 |      | 1    |      |      | 1    |   |\n",
    "| Q10 | 1 |   |   | 0.86 | 0.14 |      | 1    |      |   |\n",
    "| Q11 | 1 |   |   |      | 1    |      | 1    |      |   |\n",
    "| Q12 |   |   | 1 | 1    |      |      | 1    |      |   |\n",
    "| Q13 | 1 |   |   | 0.62 | 0.38 |      | 1    |      |   |\n",
    "| Q14 |   |   | 1 |      | 0.48 | 0.52 |      |      | 1 |\n",
    "| Q15 |   |   | 1 |      | 0.48 | 0.52 |      |      | 1 |\n",
    "| Q16 |   | 1 |   |      | 1    |      |      | 1    |   |\n",
    "| Q17 | 1 |   |   | 1    |      |      | 1    |      |   |\n",
    "| Q18 | 1 |   |   | 1    |      |      | 1    |      |   |\n",
    "| Q19 |   | 1 |   |      | 1    |      | 1    |      |   |\n",
    "| Q20 | 1 |   |   | 1    |      |      | 1    |      |   |\n",
    "| Q21 |   | 1 |   |      | 1    |      |      | 1    |   |\n",
    "| Q22 |   | 1 |   | 0.66 | 0.34 |      | 1    |      |   |\n",
    "| Q23 |   |   | 1 |      | 0.34 | 0.66 |      | 1    |   |\n",
    "| Q24 |   | 1 |   |      | 1    |      |      | 1    |   |\n",
    "| Q25 |   | 1 |   | 0.66 | 0.34 |      | 0.78 | 0.22 |   |\n",
    "| Q26 | 1 |   |   |      | 1    |      | 1    |      |   |\n",
    "| Q27 |   |   | 1 |      | 0.48 | 0.52 |      |      | 1 |\n",
    "| Q28 |   |   | 1 |      |      | 1    |      |      | 1 |\n",
    "| Q29 |   |   | 1 |      |      | 1    |      |      | 1 |\n",
    "| Q30 | 1 |   |   | 1    |      |      | 1    |      |   |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15795981",
   "metadata": {},
   "source": [
    "- The table presents the aggregated labelling results (e.g., a score of 0.5 indicates that GPT-4 selected that particular label in half of the 50 runs (i.e., 25 times)). \n",
    "- We see the probabilistic nature of the labelling, with many questions being labelled differently on different runs. \n",
    "- And when the train set is larger it reduced the variation over runs.\n",
    "\n",
    "Explanation:\n",
    "- From the first column we see Q5 is labelled as LLQ by human, Q22 as DRQ and Q28 as GDQ. \n",
    "- Now we want to compare this to aggregated labelling results from the training set with size 60. We see some 100% match and some partial match. For example – For the  Question #4 human labelled as GDQ and we see it was also labeled as GDQ by AI across all runs. For the case of partial match, we see human labeled the Question #15 as GDQ, but GPT labelled as DRQ for 48% of the time and for 52% of the time it was labeled as GDQ.\n",
    "- We see only one partical match (Question #25) from the training set with size 60.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
